Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 6s 231ms/step - loss: 9.8120 - sequential_1_loss: 7.3565 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 1.0510 - val_sequential_1_loss: 0.4510 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 49.3826 - sequential_1_loss: 11.1063 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9270 - val_sequential_1_loss: 0.3270 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 52.1193 - sequential_1_loss: 28.6178 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8853 - val_sequential_1_loss: 0.2853 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 19.1389 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8743 - val_sequential_1_loss: 0.2743 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 128.1876 - sequential_1_loss: 96.3676 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9515 - val_sequential_1_loss: 0.3515 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 13.0221 - sequential_1_loss: 13.0221 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9243 - val_sequential_1_loss: 0.3243 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 60.4326 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9014 - val_sequential_1_loss: 0.3014 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 36.5190 - sequential_1_loss: 36.5190 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9131 - val_sequential_1_loss: 0.3131 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 1.3088 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9078 - val_sequential_1_loss: 0.3078 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 28.1634 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9198 - val_sequential_1_loss: 0.3198 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 46.0663 - sequential_1_loss: 26.2517 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8993 - val_sequential_1_loss: 0.2993 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.5630 - sequential_1_loss: 0.5630 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8969 - val_sequential_1_loss: 0.2969 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 9.3534 - sequential_1_loss: 9.3534 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8992 - val_sequential_1_loss: 0.2992 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 6.6984 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.8993 - val_sequential_1_loss: 0.2993 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 5.0470 - sequential_1_loss: 1.7212 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8993 - val_sequential_1_loss: 0.2993 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 1.0231 - sequential_1_loss: 0.6188 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9003 - val_sequential_1_loss: 0.3003 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 1.1025 - sequential_1_loss: 0.2069 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.8994 - val_sequential_1_loss: 0.2994 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8824 - sequential_1_loss: 0.2861 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8997 - val_sequential_1_loss: 0.2997 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9019 - sequential_1_loss: 0.2751 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9002 - val_sequential_1_loss: 0.3002 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9360 - sequential_1_loss: 0.3854 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9006 - val_sequential_1_loss: 0.3006 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.6331 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9416 - sequential_1_loss: 0.5318 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8051 - sequential_1_loss: 0.2863 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9001 - val_sequential_1_loss: 0.3001 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.1914 - sequential_1_loss: 0.1914 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9002 - val_sequential_1_loss: 0.3002 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9326 - sequential_1_loss: 0.9326 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.8999 - val_sequential_1_loss: 0.2999 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9032 - val_sequential_1_loss: 0.3032 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 1.8817 - sequential_1_loss: 0.0000e+00 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9001 - val_sequential_1_loss: 0.3001 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8494 - sequential_1_loss: 0.1691 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9009 - val_sequential_1_loss: 0.3009 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8782 - sequential_1_loss: 0.2585 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9003 - val_sequential_1_loss: 0.3003 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9017 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9003 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8997 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 7ms/step - loss: 0.9006 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9019 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8999 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8993 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9006 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9008 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8996 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8989 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8997 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9016 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 7ms/step - loss: 0.8980 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9022 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9006 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8997 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9010 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8997 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8988 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9008 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8979 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9003 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9002 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8998 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9003 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8995 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8991 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9005 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9005 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8987 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9001 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8988 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9007 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.7500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 0.7500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.5000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9001 - val_sequential_1_loss: 0.3001 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.5000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9011 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9004 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8998 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8998 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9001 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8950 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8960 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 0.2500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 0.5000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.7500
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8996 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9054 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9025 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8949 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9053 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8987 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9012 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9003 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9044 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9002 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9029 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8963 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9025 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 1s 19ms/step - loss: 0.8985 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9022 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8994 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9002 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8979 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8999 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9058 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8963 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9054 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9054 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8949 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8976 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8977 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9060 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8955 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8993 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9044 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9053 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8927 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9063 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8949 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9069 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8944 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9080 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8882 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9064 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8935 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8935 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8929 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9044 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8907 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9079 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9065 - sequential_1_loss: 0.3044 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9091 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8943 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9066 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9051 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8951 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8917 - sequential_1_loss: 0.2939 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9069 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8925 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9083 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8904 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9103 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8909 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9058 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9056 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8886 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9063 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3051 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9071 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8945 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8899 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9099 - sequential_1_loss: 0.3061 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9126 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9066 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8936 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8938 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8944 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9053 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8947 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8916 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8983 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8963 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9075 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8950 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8991 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8939 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8921 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8943 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8951 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8936 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9062 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9050 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9061 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8919 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9107 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9070 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8917 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8955 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8963 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8891 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8963 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8924 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9054 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9118 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9015 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9053 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8930 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9050 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9064 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8891 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9050 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8921 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8889 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8908 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2943 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9154 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9101 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8947 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8942 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8926 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8951 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9100 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9144 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9069 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9095 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9069 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9066 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9065 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8944 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9063 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9077 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9049 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8957 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8951 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9013 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8959 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8966 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9044 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9065 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9051 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9053 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9056 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8957 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8936 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8947 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9105 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8960 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8955 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8917 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8929 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8955 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8936 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8963 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8928 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9076 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8933 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8957 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8881 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9094 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9093 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9044 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9071 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3068 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8934 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9066 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9076 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8934 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8950 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8951 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8860 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8957 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8934 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8933 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8920 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9054 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9061 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8930 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8879 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8913 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8878 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8848 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9164 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3108 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8820 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8910 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9049 - sequential_1_loss: 0.3075 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8882 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8949 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9272 - sequential_1_loss: 0.3113 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9244 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9127 - sequential_1_loss: 0.3078 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9064 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9070 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8847 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9088 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8919 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8920 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8921 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9116 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9138 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8883 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8950 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8910 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.3130 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9102 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9101 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9122 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8916 - sequential_1_loss: 0.2914 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9085 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9063 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2917 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9288 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9108 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9051 - sequential_1_loss: 0.3096 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8845 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9149 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9127 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9069 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9144 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9164 - sequential_1_loss: 0.3052 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9109 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9088 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9085 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9072 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8955 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9121 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8922 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8929 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8886 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9090 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9089 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9086 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8940 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9040 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8919 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9098 - sequential_1_loss: 0.3105 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9011 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9143 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.2931 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8925 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9061 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9056 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9086 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8942 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9100 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8907 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8912 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8915 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9090 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2947 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8943 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8907 - sequential_1_loss: 0.2939 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9074 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8996 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9070 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8947 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8949 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3051 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9109 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9067 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9058 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9065 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8989 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8988 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8973 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9067 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8992 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9085 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8998 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8951 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8960 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8935 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9035 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8974 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9036 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8980 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9061 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8957 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9020 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9022 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8974 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9006 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8902 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8950 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9046 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8980 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8942 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8915 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8960 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8959 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8975 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8974 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9008 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8945 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9087 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9003 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9044 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9070 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9000 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9078 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8874 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8967 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9028 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9040 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9056 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8962 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9020 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9065 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9009 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8950 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9060 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8978 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8923 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9030 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8959 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8910 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9060 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8983 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8951 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8995 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9034 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9044 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8926 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9037 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8940 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9091 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9057 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9073 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8986 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9016 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9031 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9038 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8973 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9062 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8965 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9061 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9021 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9001 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9061 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9019 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8987 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9060 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8988 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9088 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8939 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8911 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9027 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8999 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8861 - sequential_1_loss: 0.2918 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9016 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8960 - sequential_1_loss: 0.2939 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8991 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9031 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9040 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9023 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8916 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8997 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9055 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8960 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9098 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9020 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8904 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8992 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8933 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8998 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9065 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8916 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9024 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8945 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8939 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8930 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9057 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9069 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9002 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9062 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8917 - sequential_1_loss: 0.2930 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9006 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8963 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9065 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9031 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9028 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9084 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8927 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8977 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9003 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8957 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9121 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8880 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9103 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8907 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9045 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8980 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9077 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9127 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8959 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9093 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9025 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8966 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8834 - sequential_1_loss: 0.2921 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9044 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9020 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9094 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8923 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9011 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3061 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9007 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8914 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8939 - sequential_1_loss: 0.2947 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8936 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9009 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8973 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8953 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8992 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9096 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8935 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8976 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9051 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8941 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9056 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8951 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8907 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9092 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8995 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9085 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8921 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8900 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9086 - sequential_1_loss: 0.3084 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9063 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9064 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8958 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9026 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8883 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8899 - sequential_1_loss: 0.2930 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8884 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2908 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9064 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8858 - sequential_1_loss: 0.2931 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8994 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9064 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8998 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8978 - sequential_1_loss: 0.2939 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8971 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9215 - sequential_1_loss: 0.3097 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9158 - sequential_1_loss: 0.3093 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8897 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8912 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9080 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9051 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8923 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8945 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8954 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9025 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8927 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8951 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8944 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8912 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9154 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9020 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9102 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9093 - sequential_1_loss: 0.3076 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8933 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8876 - sequential_1_loss: 0.2943 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9072 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8954 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8952 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8942 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9084 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9135 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8907 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9059 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9049 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8971 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8929 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8828 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8912 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8944 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9076 - sequential_1_loss: 0.3131 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9048 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9279 - sequential_1_loss: 0.3162 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8987 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8949 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8896 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9089 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9091 - sequential_1_loss: 0.3068 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8863 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9107 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9051 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9015 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8929 - sequential_1_loss: 0.2913 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8955 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8925 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9074 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9139 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8873 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9103 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8915 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8939 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9049 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8925 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9023 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8913 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9114 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9109 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8923 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8924 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9131 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8934 - sequential_1_loss: 0.2918 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8982 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9063 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8912 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8957 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8896 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9108 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9029 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8936 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9110 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9001 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8926 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8934 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9118 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9090 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8901 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8968 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9092 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8794 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8977 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8865 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8930 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8804 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8965 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8972 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8935 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8771 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8957 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9105 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8891 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9104 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8921 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8908 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8923 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9134 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8832 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8944 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8793 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9163 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8814 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8954 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9088 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9195 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9210 - sequential_1_loss: 0.3096 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8891 - sequential_1_loss: 0.3081 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8838 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8996 - sequential_1_loss: 0.3138 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9048 - sequential_1_loss: 0.2926 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8788 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2908 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9219 - sequential_1_loss: 0.3051 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8942 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8859 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8834 - sequential_1_loss: 0.2856 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9058 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8939 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9089 - sequential_1_loss: 0.3146 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9007 - sequential_1_loss: 0.2828 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8999 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9060 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9009 - sequential_1_loss: 0.3132 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8896 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9100 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8894 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8958 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9127 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9032 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9189 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9051 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8876 - sequential_1_loss: 0.2827 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8805 - sequential_1_loss: 0.2943 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8984 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9245 - sequential_1_loss: 0.3117 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9017 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.2900 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8692 - sequential_1_loss: 0.2775 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9003 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9182 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9044 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8684 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9109 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9241 - sequential_1_loss: 0.3093 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.2896 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9424 - sequential_1_loss: 0.3184 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8908 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9085 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8941 - sequential_1_loss: 0.2845 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9116 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9076 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9013 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9160 - sequential_1_loss: 0.3111 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8858 - sequential_1_loss: 0.2854 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9246 - sequential_1_loss: 0.3150 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8710 - sequential_1_loss: 0.2888 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8693 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9027 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9268 - sequential_1_loss: 0.3089 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8929 - sequential_1_loss: 0.2865 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8811 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8988 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8917 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9089 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9162 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8814 - sequential_1_loss: 0.2883 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8732 - sequential_1_loss: 0.2838 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8961 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9296 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9371 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9071 - sequential_1_loss: 0.2880 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9081 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9085 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8780 - sequential_1_loss: 0.2798 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.3112 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9087 - sequential_1_loss: 0.3201 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8889 - sequential_1_loss: 0.2905 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8795 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8892 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8921 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8885 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9199 - sequential_1_loss: 0.3091 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9071 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8902 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8804 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8963 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9033 - sequential_1_loss: 0.2905 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9223 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9221 - sequential_1_loss: 0.3069 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9100 - sequential_1_loss: 0.3066 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8897 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9013 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9217 - sequential_1_loss: 0.3143 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9080 - sequential_1_loss: 0.3136 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3147 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8846 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9158 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8769 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8794 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8934 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9077 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9166 - sequential_1_loss: 0.3118 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8915 - sequential_1_loss: 0.3040 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9212 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8923 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.2880 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9101 - sequential_1_loss: 0.2900 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9172 - sequential_1_loss: 0.3114 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8964 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8835 - sequential_1_loss: 0.2915 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8851 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9117 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9139 - sequential_1_loss: 0.3100 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8816 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9171 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8829 - sequential_1_loss: 0.2864 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9026 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9065 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9096 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9106 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9005 - sequential_1_loss: 0.2916 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8919 - sequential_1_loss: 0.2877 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9157 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9067 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9087 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9333 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8922 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9095 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9118 - sequential_1_loss: 0.3069 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9277 - sequential_1_loss: 0.3153 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9220 - sequential_1_loss: 0.3097 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8853 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9399 - sequential_1_loss: 0.3164 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8840 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8899 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8865 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8847 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8946 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8719 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8841 - sequential_1_loss: 0.2904 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9098 - sequential_1_loss: 0.3178 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8858 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9140 - sequential_1_loss: 0.2934 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9100 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9173 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9006 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8778 - sequential_1_loss: 0.2903 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8873 - sequential_1_loss: 0.2926 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9053 - sequential_1_loss: 0.3117 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8917 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9050 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9077 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8845 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8649 - sequential_1_loss: 0.2867 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9152 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8898 - sequential_1_loss: 0.2925 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9063 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9122 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8809 - sequential_1_loss: 0.2908 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9136 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9259 - sequential_1_loss: 0.3096 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8862 - sequential_1_loss: 0.2920 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8979 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9111 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9098 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8973 - sequential_1_loss: 0.2865 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8944 - sequential_1_loss: 0.3040 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8711 - sequential_1_loss: 0.2803 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9304 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9266 - sequential_1_loss: 0.3175 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9171 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8722 - sequential_1_loss: 0.2877 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8963 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9103 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8654 - sequential_1_loss: 0.2865 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9101 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8947 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9134 - sequential_1_loss: 0.3144 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9043 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8749 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8913 - sequential_1_loss: 0.2921 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9133 - sequential_1_loss: 0.3115 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8981 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9131 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8700 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9273 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8848 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9145 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9080 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9206 - sequential_1_loss: 0.2925 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8844 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8869 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9159 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8784 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8928 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.3108 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9183 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9095 - sequential_1_loss: 0.3165 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8804 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9042 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8896 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9041 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.4643 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9072 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8897 - sequential_1_loss: 0.2899 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3069 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9102 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9118 - sequential_1_loss: 0.3076 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8890 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8819 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8809 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8865 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8916 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8891 - sequential_1_loss: 0.3130 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9018 - sequential_1_loss: 0.2872 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9197 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9151 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9084 - sequential_1_loss: 0.3121 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9008 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8774 - sequential_1_loss: 0.2912 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9005 - sequential_1_loss: 0.3106 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.2898 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8930 - sequential_1_loss: 0.3040 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9107 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9048 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8928 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9077 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8862 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9093 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8923 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9251 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9387 - sequential_1_loss: 0.3133 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9115 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9210 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8898 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8867 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9000 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8817 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9002 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8972 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8721 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9111 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8868 - sequential_1_loss: 0.2873 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8809 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8841 - sequential_1_loss: 0.2947 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8816 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9143 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8805 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8886 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9352 - sequential_1_loss: 0.3144 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8967 - sequential_1_loss: 0.3081 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8875 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8982 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3162 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.3115 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9020 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9262 - sequential_1_loss: 0.3130 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8724 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8964 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8705 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9119 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8934 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9014 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9306 - sequential_1_loss: 0.3158 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9133 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8944 - sequential_1_loss: 0.3122 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9178 - sequential_1_loss: 0.3235 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9193 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9138 - sequential_1_loss: 0.2864 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8957 - sequential_1_loss: 0.3116 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8913 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9012 - sequential_1_loss: 0.2884 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8793 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8918 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9170 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9163 - sequential_1_loss: 0.3238 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9288 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8933 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8892 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8739 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9208 - sequential_1_loss: 0.3141 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8886 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9371 - sequential_1_loss: 0.3190 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9000 - sequential_1_loss: 0.2938 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9093 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9031 - sequential_1_loss: 0.3150 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8847 - sequential_1_loss: 0.3101 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9080 - sequential_1_loss: 0.3116 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8896 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9069 - sequential_1_loss: 0.3176 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9253 - sequential_1_loss: 0.3164 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8905 - sequential_1_loss: 0.2887 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8783 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9111 - sequential_1_loss: 0.2915 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9369 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8744 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8972 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8913 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9170 - sequential_1_loss: 0.3156 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9039 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9125 - sequential_1_loss: 0.3150 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9141 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8755 - sequential_1_loss: 0.2894 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8906 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9095 - sequential_1_loss: 0.3066 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8738 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9083 - sequential_1_loss: 0.3061 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9022 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8828 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8887 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9150 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9095 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9067 - sequential_1_loss: 0.3061 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8848 - sequential_1_loss: 0.2902 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9082 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8993 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8889 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9209 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8799 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8909 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9068 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9013 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8813 - sequential_1_loss: 0.2849 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9187 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9125 - sequential_1_loss: 0.3052 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9174 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9139 - sequential_1_loss: 0.3044 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8871 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9110 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8852 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9044 - sequential_1_loss: 0.3136 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8906 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9113 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8897 - sequential_1_loss: 0.2904 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9151 - sequential_1_loss: 0.3171 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9028 - sequential_1_loss: 0.3118 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8897 - sequential_1_loss: 0.2892 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9137 - sequential_1_loss: 0.3129 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9068 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9020 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9183 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9183 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9146 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9178 - sequential_1_loss: 0.2947 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8907 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9098 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8960 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8933 - sequential_1_loss: 0.2866 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8706 - sequential_1_loss: 0.2884 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8913 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8902 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8947 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8871 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9171 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9089 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9058 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9047 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9056 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9079 - sequential_1_loss: 0.3051 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9092 - sequential_1_loss: 0.3107 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8962 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9054 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9237 - sequential_1_loss: 0.3061 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9081 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8877 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9154 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8798 - sequential_1_loss: 0.2849 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8827 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8900 - sequential_1_loss: 0.2873 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8975 - sequential_1_loss: 0.3091 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8928 - sequential_1_loss: 0.2920 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9088 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9117 - sequential_1_loss: 0.3109 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9096 - sequential_1_loss: 0.3078 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9210 - sequential_1_loss: 0.3164 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9148 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9128 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9116 - sequential_1_loss: 0.3221 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9112 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9254 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8906 - sequential_1_loss: 0.2914 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8923 - sequential_1_loss: 0.3097 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8928 - sequential_1_loss: 0.2896 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8908 - sequential_1_loss: 0.2859 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8699 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9023 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9174 - sequential_1_loss: 0.3141 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8875 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9228 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9168 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8814 - sequential_1_loss: 0.2814 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8888 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8962 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8876 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8899 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9114 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9166 - sequential_1_loss: 0.3116 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9129 - sequential_1_loss: 0.3066 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9282 - sequential_1_loss: 0.3189 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9054 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9032 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9044 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9056 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8938 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9143 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9087 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9028 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9109 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9126 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8989 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9278 - sequential_1_loss: 0.3118 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8893 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8742 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8838 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8828 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8997 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9134 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9090 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9029 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9218 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8942 - sequential_1_loss: 0.2860 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9104 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9128 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9124 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9094 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9113 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8862 - sequential_1_loss: 0.2931 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9089 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9043 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8953 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9120 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8824 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2925 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9136 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8968 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - sequential_1_loss: 0.2889 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8950 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8938 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8891 - sequential_1_loss: 0.2914 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9087 - sequential_1_loss: 0.3081 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8810 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8903 - sequential_1_loss: 0.2931 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8965 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8980 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8946 - sequential_1_loss: 0.2908 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9001 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9015 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8868 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8986 - sequential_1_loss: 0.3124 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9063 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9098 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9059 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9019 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9092 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9118 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8906 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8875 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8976 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9030 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9098 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9079 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8878 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8874 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9093 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9065 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9060 - sequential_1_loss: 0.3099 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8837 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8915 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8827 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8849 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8782 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9093 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9132 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8995 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9037 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8808 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8904 - sequential_1_loss: 0.2881 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8933 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9135 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8768 - sequential_1_loss: 0.2924 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8929 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8976 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9095 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.5000 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9026 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9134 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8716 - sequential_1_loss: 0.2887 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9019 - sequential_1_loss: 0.2924 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9164 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9169 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9067 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8932 - sequential_1_loss: 0.2891 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8917 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8979 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8846 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8941 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9002 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9153 - sequential_1_loss: 0.3170 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8764 - sequential_1_loss: 0.2891 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9135 - sequential_1_loss: 0.3084 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9132 - sequential_1_loss: 0.3084 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8873 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9202 - sequential_1_loss: 0.3106 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9083 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9157 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9034 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9168 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8863 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9175 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8933 - sequential_1_loss: 0.2830 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8913 - sequential_1_loss: 0.2899 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8931 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9084 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8891 - sequential_1_loss: 0.2902 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8881 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8879 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9016 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8862 - sequential_1_loss: 0.2842 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8918 - sequential_1_loss: 0.2913 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9112 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.4286 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8992 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9138 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.4286 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9121 - sequential_1_loss: 0.3156 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8966 - sequential_1_loss: 0.2943 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.5357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8985 - sequential_1_loss: 0.3112 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9129 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8968 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.9056 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.4286 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8952 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.4286 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9201 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.4286 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8908 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9065 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8845 - sequential_1_loss: 0.2947 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.4286 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8898 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8790 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9206 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9070 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9144 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8965 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9239 - sequential_1_loss: 0.3094 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9041 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8799 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8960 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9024 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8849 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9115 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8898 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8977 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8913 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8982 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9134 - sequential_1_loss: 0.3100 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.5000 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9061 - sequential_1_loss: 0.2943 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.3068 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9295 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9071 - sequential_1_loss: 0.2884 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9082 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8979 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.5000 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9042 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9306 - sequential_1_loss: 0.3171 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8900 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9056 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.4286 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8941 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.5000 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8891 - sequential_1_loss: 0.3117 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.5000 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8808 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - sequential_1_loss: 0.3108 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9065 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9046 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8758 - sequential_1_loss: 0.2874 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8765 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9098 - sequential_1_loss: 0.2931 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8846 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9038 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9110 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8838 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9034 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9140 - sequential_1_loss: 0.3091 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.4643 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8886 - sequential_1_loss: 0.3069 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9080 - sequential_1_loss: 0.2854 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9042 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.4286 - sequential_1_acc_1: 0.5000 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9043 - sequential_1_loss: 0.3115 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8866 - sequential_1_loss: 0.2899 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9143 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9091 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8767 - sequential_1_loss: 0.2857 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9190 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9004 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8953 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8859 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8993 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8875 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9194 - sequential_1_loss: 0.3129 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9329 - sequential_1_loss: 0.3122 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9126 - sequential_1_loss: 0.3191 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8842 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8907 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8884 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9002 - sequential_1_loss: 0.3138 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9021 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8732 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9187 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9079 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.4643 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8820 - sequential_1_loss: 0.2883 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9030 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9076 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9205 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9087 - sequential_1_loss: 0.3068 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9040 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9106 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9072 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8842 - sequential_1_loss: 0.2927 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9234 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8784 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8894 - sequential_1_loss: 0.2905 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9191 - sequential_1_loss: 0.3148 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8628 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8955 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9167 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9019 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8972 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8837 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8912 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9034 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8891 - sequential_1_loss: 0.2859 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8958 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9191 - sequential_1_loss: 0.3139 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9137 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9032 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9166 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9087 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9036 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8945 - sequential_1_loss: 0.2890 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9145 - sequential_1_loss: 0.3089 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8788 - sequential_1_loss: 0.2861 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9131 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8892 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - sequential_1_loss: 0.3127 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8712 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9063 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8714 - sequential_1_loss: 0.2808 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9131 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.4643 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8693 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9042 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9404 - sequential_1_loss: 0.3105 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9002 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9233 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9180 - sequential_1_loss: 0.2927 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8791 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9005 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8895 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9107 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9010 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9034 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9018 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8903 - sequential_1_loss: 0.2875 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8847 - sequential_1_loss: 0.2912 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8901 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9173 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8970 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8798 - sequential_1_loss: 0.2888 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8789 - sequential_1_loss: 0.2892 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9128 - sequential_1_loss: 0.3106 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8813 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8970 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8943 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9190 - sequential_1_loss: 0.3158 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8799 - sequential_1_loss: 0.2916 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9221 - sequential_1_loss: 0.3106 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8728 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8801 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.4286 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8872 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9253 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9013 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8911 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8913 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9085 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8522 - sequential_1_loss: 0.2762 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9140 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8888 - sequential_1_loss: 0.2934 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8580 - sequential_1_loss: 0.2865 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9054 - sequential_1_loss: 0.2914 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9202 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9127 - sequential_1_loss: 0.3131 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8923 - sequential_1_loss: 0.2771 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 3ms/step - loss: 0.8919 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8975 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8774 - sequential_1_loss: 0.3079 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9104 - sequential_1_loss: 0.3109 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9014 - sequential_1_loss: 0.2938 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8754 - sequential_1_loss: 0.2838 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.2913 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9083 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8985 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8803 - sequential_1_loss: 0.2895 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9033 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8971 - sequential_1_loss: 0.3124 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9102 - sequential_1_loss: 0.3052 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9100 - sequential_1_loss: 0.3119 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9034 - sequential_1_loss: 0.2908 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8759 - sequential_1_loss: 0.2847 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8832 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8842 - sequential_1_loss: 0.2852 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8863 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9001 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9430 - sequential_1_loss: 0.3166 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9147 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9223 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8789 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8557 - sequential_1_loss: 0.2780 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8927 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9197 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9016 - sequential_1_loss: 0.2873 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8898 - sequential_1_loss: 0.3074 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8890 - sequential_1_loss: 0.3089 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9407 - sequential_1_loss: 0.3163 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8684 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8942 - sequential_1_loss: 0.2920 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8802 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8839 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9133 - sequential_1_loss: 0.3150 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8963 - sequential_1_loss: 0.2839 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9202 - sequential_1_loss: 0.3161 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8891 - sequential_1_loss: 0.2896 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8814 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8701 - sequential_1_loss: 0.2846 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9081 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8682 - sequential_1_loss: 0.2705 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8865 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9124 - sequential_1_loss: 0.3151 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8959 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8904 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9308 - sequential_1_loss: 0.3150 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8890 - sequential_1_loss: 0.3110 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9300 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8765 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9216 - sequential_1_loss: 0.3215 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9257 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8863 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9376 - sequential_1_loss: 0.3303 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8871 - sequential_1_loss: 0.3183 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9205 - sequential_1_loss: 0.3191 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8844 - sequential_1_loss: 0.2780 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9190 - sequential_1_loss: 0.3111 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8925 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8789 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9212 - sequential_1_loss: 0.3144 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.2906 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8838 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9151 - sequential_1_loss: 0.3163 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8872 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8749 - sequential_1_loss: 0.2737 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9304 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9001 - sequential_1_loss: 0.3111 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9268 - sequential_1_loss: 0.3244 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8803 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8773 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8998 - sequential_1_loss: 0.3112 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8698 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8701 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9007 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9053 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9049 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8949 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8920 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9176 - sequential_1_loss: 0.3075 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8936 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8718 - sequential_1_loss: 0.2705 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9108 - sequential_1_loss: 0.2801 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8758 - sequential_1_loss: 0.2688 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9544 - sequential_1_loss: 0.3340 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9402 - sequential_1_loss: 0.3162 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9207 - sequential_1_loss: 0.3111 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8823 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9385 - sequential_1_loss: 0.3138 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8873 - sequential_1_loss: 0.2841 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8499 - sequential_1_loss: 0.2684 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9081 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9065 - sequential_1_loss: 0.3044 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8884 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9050 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9598 - sequential_1_loss: 0.3208 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8856 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9274 - sequential_1_loss: 0.3142 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9089 - sequential_1_loss: 0.3172 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8657 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9108 - sequential_1_loss: 0.3144 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9226 - sequential_1_loss: 0.3145 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9025 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9254 - sequential_1_loss: 0.3131 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8997 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8938 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9040 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8950 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8672 - sequential_1_loss: 0.2831 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9209 - sequential_1_loss: 0.3170 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9158 - sequential_1_loss: 0.3138 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9300 - sequential_1_loss: 0.3238 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8841 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9107 - sequential_1_loss: 0.3069 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9222 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9068 - sequential_1_loss: 0.3154 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8599 - sequential_1_loss: 0.3105 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8832 - sequential_1_loss: 0.2864 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9278 - sequential_1_loss: 0.3116 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9393 - sequential_1_loss: 0.3175 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8823 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9025 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9064 - sequential_1_loss: 0.3144 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9212 - sequential_1_loss: 0.3091 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8822 - sequential_1_loss: 0.2887 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8962 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9280 - sequential_1_loss: 0.3257 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9277 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8878 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8984 - sequential_1_loss: 0.3119 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8975 - sequential_1_loss: 0.2908 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8993 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9100 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9043 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9210 - sequential_1_loss: 0.3109 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9127 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.3929 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8426 - sequential_1_loss: 0.2750 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8893 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8913 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9175 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9001 - sequential_1_loss: 0.3138 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9010 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9253 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8938 - sequential_1_loss: 0.2890 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9036 - sequential_1_loss: 0.3184 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9397 - sequential_1_loss: 0.3190 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9073 - sequential_1_loss: 0.3212 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9108 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9259 - sequential_1_loss: 0.3197 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9064 - sequential_1_loss: 0.3119 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8963 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9155 - sequential_1_loss: 0.3167 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8844 - sequential_1_loss: 0.2828 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9058 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9114 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9060 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9378 - sequential_1_loss: 0.3171 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9251 - sequential_1_loss: 0.3125 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9022 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9281 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9001 - sequential_1_loss: 0.3020 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9023 - sequential_1_loss: 0.2905 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8911 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8806 - sequential_1_loss: 0.2876 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9061 - sequential_1_loss: 0.3137 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9050 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9230 - sequential_1_loss: 0.3119 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8881 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9002 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8910 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9100 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8985 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9058 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8899 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9116 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9300 - sequential_1_loss: 0.3253 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9098 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9148 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8907 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9130 - sequential_1_loss: 0.3075 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8834 - sequential_1_loss: 0.2834 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8920 - sequential_1_loss: 0.3093 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8982 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9159 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9056 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8881 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.3929 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8960 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9277 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8665 - sequential_1_loss: 0.2892 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8795 - sequential_1_loss: 0.2877 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8974 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9060 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9063 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9077 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8965 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9032 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9043 - sequential_1_loss: 0.2890 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9025 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8984 - sequential_1_loss: 0.3160 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8936 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8830 - sequential_1_loss: 0.2903 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9126 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8658 - sequential_1_loss: 0.2890 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8779 - sequential_1_loss: 0.2920 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8921 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9181 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9127 - sequential_1_loss: 0.3094 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8843 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9141 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9050 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8902 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.3571 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8832 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9070 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8889 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9228 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9186 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8877 - sequential_1_loss: 0.2817 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8938 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8946 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9168 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8861 - sequential_1_loss: 0.2863 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9108 - sequential_1_loss: 0.3066 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9252 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8954 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8869 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9066 - sequential_1_loss: 0.3255 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9112 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8944 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9041 - sequential_1_loss: 0.2895 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8908 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8865 - sequential_1_loss: 0.2920 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9013 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8923 - sequential_1_loss: 0.2906 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8913 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8989 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9040 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9078 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8955 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8981 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8947 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8944 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9217 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8948 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8853 - sequential_1_loss: 0.2872 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9155 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9163 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8965 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8911 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8911 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8849 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8922 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8782 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9134 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8935 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8906 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9078 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9103 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9266 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9006 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.3044 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8990 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9035 - sequential_1_loss: 0.3076 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9181 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8637 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9178 - sequential_1_loss: 0.3120 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8792 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9254 - sequential_1_loss: 0.3093 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9131 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8909 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9009 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8936 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8971 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8792 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8899 - sequential_1_loss: 0.3084 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8961 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8941 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8682 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8946 - sequential_1_loss: 0.2893 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9139 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8990 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8838 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9089 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8969 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9073 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9072 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9293 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8663 - sequential_1_loss: 0.2840 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9085 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9183 - sequential_1_loss: 0.3102 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9130 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8759 - sequential_1_loss: 0.2783 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9038 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9076 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9124 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8934 - sequential_1_loss: 0.2899 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8848 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8752 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8979 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9288 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9140 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8913 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8797 - sequential_1_loss: 0.2783 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8677 - sequential_1_loss: 0.2869 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9194 - sequential_1_loss: 0.3105 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8893 - sequential_1_loss: 0.2843 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8941 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9348 - sequential_1_loss: 0.3153 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8820 - sequential_1_loss: 0.2893 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9107 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9400 - sequential_1_loss: 0.3176 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9051 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9221 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9048 - sequential_1_loss: 0.2893 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8770 - sequential_1_loss: 0.3135 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8966 - sequential_1_loss: 0.3068 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8907 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8741 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9447 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9015 - sequential_1_loss: 0.3161 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8883 - sequential_1_loss: 0.3112 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9178 - sequential_1_loss: 0.3154 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9112 - sequential_1_loss: 0.3115 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9003 - sequential_1_loss: 0.2807 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9222 - sequential_1_loss: 0.3204 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8635 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9307 - sequential_1_loss: 0.3210 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9016 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9070 - sequential_1_loss: 0.3119 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.2934 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8959 - sequential_1_loss: 0.2876 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9198 - sequential_1_loss: 0.2915 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9175 - sequential_1_loss: 0.3111 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8853 - sequential_1_loss: 0.2870 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8840 - sequential_1_loss: 0.2914 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9077 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9147 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9043 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8780 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9290 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9057 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9245 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9229 - sequential_1_loss: 0.3193 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.2904 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9181 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9137 - sequential_1_loss: 0.2934 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8819 - sequential_1_loss: 0.2812 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9125 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8794 - sequential_1_loss: 0.2803 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8835 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8969 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8750 - sequential_1_loss: 0.2912 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8892 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8782 - sequential_1_loss: 0.2859 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9080 - sequential_1_loss: 0.3194 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9036 - sequential_1_loss: 0.2907 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9171 - sequential_1_loss: 0.2917 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9100 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8993 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9042 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8846 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9103 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8661 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9035 - sequential_1_loss: 0.3093 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9132 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9252 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 3ms/step - loss: 0.8767 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8892 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8862 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8731 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9010 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8765 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8878 - sequential_1_loss: 0.2916 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8945 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9117 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8985 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9223 - sequential_1_loss: 0.3136 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8766 - sequential_1_loss: 0.2776 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8946 - sequential_1_loss: 0.2877 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8935 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9288 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9129 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8848 - sequential_1_loss: 0.2868 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9180 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8975 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9106 - sequential_1_loss: 0.2884 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8819 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8927 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8727 - sequential_1_loss: 0.2864 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9027 - sequential_1_loss: 0.2879 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9113 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8850 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8775 - sequential_1_loss: 0.3005 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9085 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9127 - sequential_1_loss: 0.3127 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9186 - sequential_1_loss: 0.3079 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.3238 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8748 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8873 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8855 - sequential_1_loss: 0.2973 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8885 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9060 - sequential_1_loss: 0.3181 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.3571 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8749 - sequential_1_loss: 0.2882 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8788 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9039 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8753 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8986 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9181 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8711 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8990 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9225 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8836 - sequential_1_loss: 0.2876 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9322 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.3929 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9397 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9160 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8624 - sequential_1_loss: 0.2888 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9335 - sequential_1_loss: 0.3158 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9172 - sequential_1_loss: 0.3124 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8963 - sequential_1_loss: 0.3094 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9097 - sequential_1_loss: 0.2928 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8860 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8968 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8714 - sequential_1_loss: 0.2806 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8721 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9312 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9226 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8680 - sequential_1_loss: 0.2739 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9104 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8953 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.3214 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9344 - sequential_1_loss: 0.3163 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.3571 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9048 - sequential_1_loss: 0.2883 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8857 - sequential_1_loss: 0.3040 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8864 - sequential_1_loss: 0.3051 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8922 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8769 - sequential_1_loss: 0.2884 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9020 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8877 - sequential_1_loss: 0.2848 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8993 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9182 - sequential_1_loss: 0.3106 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9119 - sequential_1_loss: 0.3111 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8620 - sequential_1_loss: 0.3080 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8927 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9858 - sequential_1_loss: 0.3290 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9122 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9290 - sequential_1_loss: 0.3135 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8534 - sequential_1_loss: 0.2647 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8902 - sequential_1_loss: 0.2739 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8991 - sequential_1_loss: 0.3222 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8798 - sequential_1_loss: 0.2757 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9091 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8836 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8770 - sequential_1_loss: 0.2887 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9302 - sequential_1_loss: 0.3205 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8961 - sequential_1_loss: 0.3096 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9319 - sequential_1_loss: 0.3276 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8684 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8786 - sequential_1_loss: 0.3113 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8991 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8932 - sequential_1_loss: 0.2858 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9183 - sequential_1_loss: 0.3122 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8702 - sequential_1_loss: 0.2883 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8752 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.3135 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8722 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9124 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8887 - sequential_1_loss: 0.3182 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9534 - sequential_1_loss: 0.3181 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9463 - sequential_1_loss: 0.3156 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9349 - sequential_1_loss: 0.3078 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8965 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9312 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.3214 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8757 - sequential_1_loss: 0.2768 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - sequential_1_loss: 0.2891 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9491 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8539 - sequential_1_loss: 0.2869 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9036 - sequential_1_loss: 0.3166 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8857 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8659 - sequential_1_loss: 0.2770 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8950 - sequential_1_loss: 0.3146 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9397 - sequential_1_loss: 0.3067 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9510 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8722 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8821 - sequential_1_loss: 0.2895 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9054 - sequential_1_loss: 0.3332 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8935 - sequential_1_loss: 0.2963 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9052 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8898 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9293 - sequential_1_loss: 0.3188 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9051 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8719 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9134 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9365 - sequential_1_loss: 0.3068 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8953 - sequential_1_loss: 0.2841 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9212 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9153 - sequential_1_loss: 0.2916 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8696 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9373 - sequential_1_loss: 0.3158 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.2842 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9007 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8954 - sequential_1_loss: 0.3159 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8971 - sequential_1_loss: 0.2900 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8888 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9095 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9049 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9145 - sequential_1_loss: 0.3127 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9002 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8794 - sequential_1_loss: 0.2851 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9371 - sequential_1_loss: 0.3040 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9183 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8938 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9141 - sequential_1_loss: 0.3129 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8822 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9330 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9077 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9159 - sequential_1_loss: 0.3076 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9355 - sequential_1_loss: 0.3125 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9411 - sequential_1_loss: 0.3256 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9233 - sequential_1_loss: 0.3133 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9076 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8969 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8806 - sequential_1_loss: 0.2833 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9109 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9132 - sequential_1_loss: 0.3155 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9084 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8941 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9000 - sequential_1_loss: 0.2830 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9156 - sequential_1_loss: 0.2927 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8971 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9208 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9220 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8800 - sequential_1_loss: 0.2837 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9188 - sequential_1_loss: 0.3044 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8964 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9187 - sequential_1_loss: 0.3144 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9113 - sequential_1_loss: 0.3019 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9114 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9130 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9100 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.3122 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9127 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9006 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8802 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8845 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8887 - sequential_1_loss: 0.3016 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9247 - sequential_1_loss: 0.3140 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9131 - sequential_1_loss: 0.3134 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8740 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9108 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8591 - sequential_1_loss: 0.2855 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8910 - sequential_1_loss: 0.3189 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9014 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9085 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8637 - sequential_1_loss: 0.2799 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9032 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9030 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8978 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8946 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9033 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8969 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9057 - sequential_1_loss: 0.3102 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9044 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9051 - sequential_1_loss: 0.3001 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8957 - sequential_1_loss: 0.2978 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8965 - sequential_1_loss: 0.2873 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8900 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8873 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9054 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8844 - sequential_1_loss: 0.3066 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8892 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9152 - sequential_1_loss: 0.3080 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8954 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2500 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9204 - sequential_1_loss: 0.3201 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8814 - sequential_1_loss: 0.2821 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9127 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9088 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9104 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9056 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8779 - sequential_1_loss: 0.2738 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8791 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.2857 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8888 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8946 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8916 - sequential_1_loss: 0.2876 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9138 - sequential_1_loss: 0.3191 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8877 - sequential_1_loss: 0.3157 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8914 - sequential_1_loss: 0.2907 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9039 - sequential_1_loss: 0.3188 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8847 - sequential_1_loss: 0.3179 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9245 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8843 - sequential_1_loss: 0.3074 - sequential_1_acc: 0.2857 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8546 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2500 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9111 - sequential_1_loss: 0.3008 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8871 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9294 - sequential_1_loss: 0.3158 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8974 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9035 - sequential_1_loss: 0.3061 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9203 - sequential_1_loss: 0.3078 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8926 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9071 - sequential_1_loss: 0.3091 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 1.0000 - val_sequential_1_acc_1: 1.0000 - val_sequential_1_acc_2: 1.0000
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9299 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8956 - sequential_1_loss: 0.3108 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9169 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9165 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9112 - sequential_1_loss: 0.3194 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8700 - sequential_1_loss: 0.2912 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8704 - sequential_1_loss: 0.2914 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9239 - sequential_1_loss: 0.3287 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2857 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8811 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8786 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9172 - sequential_1_loss: 0.3099 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8793 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8726 - sequential_1_loss: 0.2884 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8773 - sequential_1_loss: 0.2802 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9157 - sequential_1_loss: 0.3118 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9046 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8872 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9227 - sequential_1_loss: 0.3194 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8881 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9251 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8887 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.2884 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9080 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8920 - sequential_1_loss: 0.2822 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9356 - sequential_1_loss: 0.3125 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9104 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9247 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8888 - sequential_1_loss: 0.2968 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8863 - sequential_1_loss: 0.2853 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8699 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9135 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9216 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8824 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9380 - sequential_1_loss: 0.3069 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8736 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9286 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9055 - sequential_1_loss: 0.3191 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8494 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9263 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8852 - sequential_1_loss: 0.2918 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8753 - sequential_1_loss: 0.3127 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9045 - sequential_1_loss: 0.2902 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8901 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9044 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8880 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8881 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9103 - sequential_1_loss: 0.3150 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9048 - sequential_1_loss: 0.3088 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8466 - sequential_1_loss: 0.2681 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9123 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8918 - sequential_1_loss: 0.2880 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9245 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8927 - sequential_1_loss: 0.2854 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9073 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9188 - sequential_1_loss: 0.3202 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9112 - sequential_1_loss: 0.3125 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8813 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9151 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9075 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9075 - sequential_1_loss: 0.3164 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9088 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9180 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9117 - sequential_1_loss: 0.3225 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8895 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9260 - sequential_1_loss: 0.3227 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8686 - sequential_1_loss: 0.2802 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9048 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9126 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9134 - sequential_1_loss: 0.3157 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8880 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8923 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9116 - sequential_1_loss: 0.3099 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9050 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9105 - sequential_1_loss: 0.2942 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9441 - sequential_1_loss: 0.3124 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9065 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9365 - sequential_1_loss: 0.3168 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9159 - sequential_1_loss: 0.3132 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9141 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9278 - sequential_1_loss: 0.3160 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9099 - sequential_1_loss: 0.3158 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8947 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9081 - sequential_1_loss: 0.2899 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8943 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9084 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8765 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8846 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9222 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9250 - sequential_1_loss: 0.3112 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9128 - sequential_1_loss: 0.3102 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9206 - sequential_1_loss: 0.2934 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9107 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9196 - sequential_1_loss: 0.3206 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9295 - sequential_1_loss: 0.3207 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9133 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9033 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9007 - sequential_1_loss: 0.2899 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8875 - sequential_1_loss: 0.2921 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8803 - sequential_1_loss: 0.2894 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8908 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8993 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9089 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8987 - sequential_1_loss: 0.2875 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8983 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.2143 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9223 - sequential_1_loss: 0.3166 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8872 - sequential_1_loss: 0.2854 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9211 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8952 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9020 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8936 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9039 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8949 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9058 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9065 - sequential_1_loss: 0.3087 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9060 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8988 - sequential_1_loss: 0.2914 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9064 - sequential_1_loss: 0.3113 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8932 - sequential_1_loss: 0.2837 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9268 - sequential_1_loss: 0.3098 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8822 - sequential_1_loss: 0.2861 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8884 - sequential_1_loss: 0.2952 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9408 - sequential_1_loss: 0.3129 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8757 - sequential_1_loss: 0.2907 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9339 - sequential_1_loss: 0.3228 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9046 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9109 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9037 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8945 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9038 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8768 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9156 - sequential_1_loss: 0.3071 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9203 - sequential_1_loss: 0.3052 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9108 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.3081 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9268 - sequential_1_loss: 0.3126 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9158 - sequential_1_loss: 0.2959 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9040 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8878 - sequential_1_loss: 0.2824 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9031 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9154 - sequential_1_loss: 0.3179 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8891 - sequential_1_loss: 0.2834 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9020 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9090 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9261 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8958 - sequential_1_loss: 0.3101 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9253 - sequential_1_loss: 0.3110 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8900 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8879 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8873 - sequential_1_loss: 0.2895 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8961 - sequential_1_loss: 0.2955 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9140 - sequential_1_loss: 0.3098 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9103 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8883 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9035 - sequential_1_loss: 0.3086 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9047 - sequential_1_loss: 0.3151 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8988 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8999 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8889 - sequential_1_loss: 0.2915 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8991 - sequential_1_loss: 0.3028 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9083 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.2969 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9072 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9077 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9144 - sequential_1_loss: 0.3040 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8905 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.2940 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9010 - sequential_1_loss: 0.3064 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9113 - sequential_1_loss: 0.2888 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9064 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8955 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - sequential_1_loss: 0.3094 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8891 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9001 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9032 - sequential_1_loss: 0.3081 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9173 - sequential_1_loss: 0.3017 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8963 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9046 - sequential_1_loss: 0.3040 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8801 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8842 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9067 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8906 - sequential_1_loss: 0.2889 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9290 - sequential_1_loss: 0.3087 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9018 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8944 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8780 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8981 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8875 - sequential_1_loss: 0.2927 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8778 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9120 - sequential_1_loss: 0.3137 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9105 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8895 - sequential_1_loss: 0.2906 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8814 - sequential_1_loss: 0.2906 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8926 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8837 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9146 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8989 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9053 - sequential_1_loss: 0.2995 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8955 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8842 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8847 - sequential_1_loss: 0.2927 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8957 - sequential_1_loss: 0.2900 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9022 - sequential_1_loss: 0.3076 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9059 - sequential_1_loss: 0.3014 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9101 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9029 - sequential_1_loss: 0.2926 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8856 - sequential_1_loss: 0.2918 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9064 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8905 - sequential_1_loss: 0.2979 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9130 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8840 - sequential_1_loss: 0.2919 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8840 - sequential_1_loss: 0.2819 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9137 - sequential_1_loss: 0.3065 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8783 - sequential_1_loss: 0.2820 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8959 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9020 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8824 - sequential_1_loss: 0.2785 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8966 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8944 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9051 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9095 - sequential_1_loss: 0.2905 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8781 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9115 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9044 - sequential_1_loss: 0.3055 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9366 - sequential_1_loss: 0.3091 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9201 - sequential_1_loss: 0.3204 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9041 - sequential_1_loss: 0.2948 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9047 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8918 - sequential_1_loss: 0.2924 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9182 - sequential_1_loss: 0.3118 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8971 - sequential_1_loss: 0.3044 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8936 - sequential_1_loss: 0.3087 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8779 - sequential_1_loss: 0.2935 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9054 - sequential_1_loss: 0.3106 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8903 - sequential_1_loss: 0.2876 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9120 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9051 - sequential_1_loss: 0.3043 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9037 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8970 - sequential_1_loss: 0.2930 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9219 - sequential_1_loss: 0.3153 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8983 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9156 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8902 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9301 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9221 - sequential_1_loss: 0.3096 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9164 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9098 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8927 - sequential_1_loss: 0.2864 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.3053 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8910 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8998 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8801 - sequential_1_loss: 0.2862 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9073 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9142 - sequential_1_loss: 0.3126 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8965 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9082 - sequential_1_loss: 0.2950 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9024 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8958 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9027 - sequential_1_loss: 0.2894 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8977 - sequential_1_loss: 0.3098 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9093 - sequential_1_loss: 0.3106 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9024 - sequential_1_loss: 0.3139 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8951 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8974 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8725 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8855 - sequential_1_loss: 0.3078 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8866 - sequential_1_loss: 0.2964 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9094 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8634 - sequential_1_loss: 0.2816 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9072 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9117 - sequential_1_loss: 0.3109 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8750 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8891 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8973 - sequential_1_loss: 0.2809 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8848 - sequential_1_loss: 0.2894 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9053 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8883 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 3ms/step - loss: 0.9109 - sequential_1_loss: 0.3018 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9204 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8950 - sequential_1_loss: 0.3089 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9027 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8846 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8969 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9151 - sequential_1_loss: 0.3054 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8791 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9107 - sequential_1_loss: 0.3101 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8932 - sequential_1_loss: 0.2926 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9187 - sequential_1_loss: 0.3118 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9093 - sequential_1_loss: 0.3154 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8963 - sequential_1_loss: 0.2933 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9006 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9189 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9043 - sequential_1_loss: 0.3044 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8872 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9235 - sequential_1_loss: 0.3078 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8656 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8930 - sequential_1_loss: 0.2875 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8965 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9049 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8677 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8807 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9306 - sequential_1_loss: 0.3168 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8862 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8692 - sequential_1_loss: 0.2854 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8899 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9011 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9112 - sequential_1_loss: 0.3038 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9272 - sequential_1_loss: 0.3047 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8852 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8953 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9279 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8651 - sequential_1_loss: 0.2896 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9204 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9061 - sequential_1_loss: 0.3076 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8833 - sequential_1_loss: 0.3109 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8749 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8943 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9026 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9177 - sequential_1_loss: 0.3042 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9125 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8983 - sequential_1_loss: 0.3015 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8817 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8645 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8962 - sequential_1_loss: 0.2892 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9120 - sequential_1_loss: 0.3110 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9148 - sequential_1_loss: 0.3098 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9131 - sequential_1_loss: 0.3084 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9020 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9016 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8912 - sequential_1_loss: 0.2841 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - sequential_1_loss: 0.3109 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8855 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9270 - sequential_1_loss: 0.3110 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9078 - sequential_1_loss: 0.2860 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8782 - sequential_1_loss: 0.2825 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9036 - sequential_1_loss: 0.3120 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9017 - sequential_1_loss: 0.3168 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8895 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8910 - sequential_1_loss: 0.2913 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9420 - sequential_1_loss: 0.3242 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9039 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9234 - sequential_1_loss: 0.3034 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8932 - sequential_1_loss: 0.3011 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9090 - sequential_1_loss: 0.3118 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8815 - sequential_1_loss: 0.2742 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8904 - sequential_1_loss: 0.2856 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9193 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9364 - sequential_1_loss: 0.3126 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8700 - sequential_1_loss: 0.2891 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8989 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9121 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9049 - sequential_1_loss: 0.2904 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8920 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9269 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9067 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9179 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8694 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9008 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9088 - sequential_1_loss: 0.3122 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9039 - sequential_1_loss: 0.3027 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8883 - sequential_1_loss: 0.2981 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9123 - sequential_1_loss: 0.2923 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9281 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8878 - sequential_1_loss: 0.2831 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9024 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9283 - sequential_1_loss: 0.3178 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8884 - sequential_1_loss: 0.2980 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8988 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8859 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9079 - sequential_1_loss: 0.3095 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9111 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8960 - sequential_1_loss: 0.3096 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8962 - sequential_1_loss: 0.3159 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8806 - sequential_1_loss: 0.2931 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9078 - sequential_1_loss: 0.3069 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9060 - sequential_1_loss: 0.2838 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9067 - sequential_1_loss: 0.3029 - sequential_1_acc: 0.2500 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9091 - sequential_1_loss: 0.2916 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8980 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9063 - sequential_1_loss: 0.3080 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9253 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8972 - sequential_1_loss: 0.2934 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8962 - sequential_1_loss: 0.2984 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9363 - sequential_1_loss: 0.3188 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8718 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9134 - sequential_1_loss: 0.3080 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9091 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9069 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9049 - sequential_1_loss: 0.2881 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9105 - sequential_1_loss: 0.2988 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8860 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9261 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9102 - sequential_1_loss: 0.3060 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8909 - sequential_1_loss: 0.2975 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8870 - sequential_1_loss: 0.2901 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8899 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9155 - sequential_1_loss: 0.3081 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8968 - sequential_1_loss: 0.2852 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8956 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8734 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8670 - sequential_1_loss: 0.2895 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8966 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8823 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9008 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - sequential_1_loss: 0.3079 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8867 - sequential_1_loss: 0.2947 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8857 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8895 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9064 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9141 - sequential_1_loss: 0.2943 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8758 - sequential_1_loss: 0.2841 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8820 - sequential_1_loss: 0.2917 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8774 - sequential_1_loss: 0.2907 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9104 - sequential_1_loss: 0.3201 - sequential_1_acc: 0.3214 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8982 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8968 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9259 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9121 - sequential_1_loss: 0.2943 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8908 - sequential_1_loss: 0.2856 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9054 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9118 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9150 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8668 - sequential_1_loss: 0.2775 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9307 - sequential_1_loss: 0.3163 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9185 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8590 - sequential_1_loss: 0.2842 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8932 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8888 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8587 - sequential_1_loss: 0.2903 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8902 - sequential_1_loss: 0.3090 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9150 - sequential_1_loss: 0.3031 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8949 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9229 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8946 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8720 - sequential_1_loss: 0.2829 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.2143 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8936 - sequential_1_loss: 0.2965 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8984 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.2847 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8857 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9089 - sequential_1_loss: 0.3262 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8907 - sequential_1_loss: 0.2836 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9195 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8603 - sequential_1_loss: 0.2807 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8858 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8922 - sequential_1_loss: 0.2911 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8713 - sequential_1_loss: 0.3046 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8907 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9255 - sequential_1_loss: 0.3239 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8687 - sequential_1_loss: 0.2781 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8997 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9217 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.3056 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9265 - sequential_1_loss: 0.2746 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9155 - sequential_1_loss: 0.2865 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9023 - sequential_1_loss: 0.3012 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9203 - sequential_1_loss: 0.3173 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9221 - sequential_1_loss: 0.3128 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8870 - sequential_1_loss: 0.3139 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9111 - sequential_1_loss: 0.2871 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8939 - sequential_1_loss: 0.2915 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8981 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.2936 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9299 - sequential_1_loss: 0.3166 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8975 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8616 - sequential_1_loss: 0.2987 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9101 - sequential_1_loss: 0.3112 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8963 - sequential_1_loss: 0.3021 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9157 - sequential_1_loss: 0.3057 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8597 - sequential_1_loss: 0.2926 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9300 - sequential_1_loss: 0.3329 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9020 - sequential_1_loss: 0.2970 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9131 - sequential_1_loss: 0.2937 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9262 - sequential_1_loss: 0.3024 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9180 - sequential_1_loss: 0.3154 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9190 - sequential_1_loss: 0.3045 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8951 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9023 - sequential_1_loss: 0.3127 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9211 - sequential_1_loss: 0.2929 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9179 - sequential_1_loss: 0.2881 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8830 - sequential_1_loss: 0.2956 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9045 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8823 - sequential_1_loss: 0.2958 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.2962 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9125 - sequential_1_loss: 0.2927 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8915 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8721 - sequential_1_loss: 0.2861 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8988 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9132 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8910 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8788 - sequential_1_loss: 0.3049 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8927 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8874 - sequential_1_loss: 0.2886 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8774 - sequential_1_loss: 0.2990 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8781 - sequential_1_loss: 0.3030 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8837 - sequential_1_loss: 0.2882 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9011 - sequential_1_loss: 0.2820 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8592 - sequential_1_loss: 0.2837 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8713 - sequential_1_loss: 0.3076 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9086 - sequential_1_loss: 0.3041 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8606 - sequential_1_loss: 0.2667 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9036 - sequential_1_loss: 0.2794 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8943 - sequential_1_loss: 0.3050 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9149 - sequential_1_loss: 0.3051 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9205 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9067 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8954 - sequential_1_loss: 0.2992 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9195 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9261 - sequential_1_loss: 0.3169 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9145 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8862 - sequential_1_loss: 0.2918 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8704 - sequential_1_loss: 0.2974 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9439 - sequential_1_loss: 0.3194 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8891 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8806 - sequential_1_loss: 0.2910 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8888 - sequential_1_loss: 0.2869 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9331 - sequential_1_loss: 0.3126 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8846 - sequential_1_loss: 0.2812 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8885 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9121 - sequential_1_loss: 0.3188 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8873 - sequential_1_loss: 0.2823 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8667 - sequential_1_loss: 0.2993 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9153 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9268 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8982 - sequential_1_loss: 0.2852 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8651 - sequential_1_loss: 0.2812 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8907 - sequential_1_loss: 0.3009 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8842 - sequential_1_loss: 0.2860 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8976 - sequential_1_loss: 0.2957 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8809 - sequential_1_loss: 0.2906 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8940 - sequential_1_loss: 0.3023 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8947 - sequential_1_loss: 0.2997 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9061 - sequential_1_loss: 0.3077 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8992 - sequential_1_loss: 0.3022 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8871 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9043 - sequential_1_loss: 0.2976 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9182 - sequential_1_loss: 0.3232 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8974 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8894 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8979 - sequential_1_loss: 0.2777 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9290 - sequential_1_loss: 0.3112 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9152 - sequential_1_loss: 0.3032 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8915 - sequential_1_loss: 0.3179 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8973 - sequential_1_loss: 0.3013 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8855 - sequential_1_loss: 0.2795 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9333 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9025 - sequential_1_loss: 0.2951 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9014 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8931 - sequential_1_loss: 0.2983 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9012 - sequential_1_loss: 0.2967 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.2897 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9128 - sequential_1_loss: 0.2926 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8690 - sequential_1_loss: 0.2953 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9130 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8997 - sequential_1_loss: 0.2853 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8782 - sequential_1_loss: 0.2885 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8897 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8843 - sequential_1_loss: 0.2896 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9102 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9105 - sequential_1_loss: 0.3313 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9050 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9146 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9101 - sequential_1_loss: 0.2832 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9011 - sequential_1_loss: 0.2922 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9103 - sequential_1_loss: 0.2822 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9099 - sequential_1_loss: 0.3026 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9119 - sequential_1_loss: 0.3131 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9247 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9163 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9225 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9157 - sequential_1_loss: 0.3087 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9103 - sequential_1_loss: 0.3004 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9038 - sequential_1_loss: 0.3248 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8997 - sequential_1_loss: 0.2718 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8737 - sequential_1_loss: 0.2864 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9275 - sequential_1_loss: 0.3126 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.3151 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9090 - sequential_1_loss: 0.2998 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8761 - sequential_1_loss: 0.3084 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9097 - sequential_1_loss: 0.3084 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8883 - sequential_1_loss: 0.2930 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8921 - sequential_1_loss: 0.2865 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8725 - sequential_1_loss: 0.2982 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9198 - sequential_1_loss: 0.3097 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9098 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8864 - sequential_1_loss: 0.3079 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9214 - sequential_1_loss: 0.3070 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8975 - sequential_1_loss: 0.3093 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9150 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9013 - sequential_1_loss: 0.3003 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9258 - sequential_1_loss: 0.3035 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9208 - sequential_1_loss: 0.3154 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9056 - sequential_1_loss: 0.3089 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8652 - sequential_1_loss: 0.2769 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9095 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9169 - sequential_1_loss: 0.3262 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9054 - sequential_1_loss: 0.2999 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8971 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8473 - sequential_1_loss: 0.2747 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9203 - sequential_1_loss: 0.2879 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8837 - sequential_1_loss: 0.2960 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9031 - sequential_1_loss: 0.3150 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9114 - sequential_1_loss: 0.2994 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8922 - sequential_1_loss: 0.2938 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9033 - sequential_1_loss: 0.3085 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8847 - sequential_1_loss: 0.3109 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8822 - sequential_1_loss: 0.2887 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9084 - sequential_1_loss: 0.3058 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8772 - sequential_1_loss: 0.2945 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8928 - sequential_1_loss: 0.2971 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9306 - sequential_1_loss: 0.3153 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9486 - sequential_1_loss: 0.3140 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9163 - sequential_1_loss: 0.2985 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9077 - sequential_1_loss: 0.3139 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9286 - sequential_1_loss: 0.3099 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9104 - sequential_1_loss: 0.3092 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8934 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9044 - sequential_1_loss: 0.2949 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8796 - sequential_1_loss: 0.2961 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8939 - sequential_1_loss: 0.3080 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8868 - sequential_1_loss: 0.3203 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8991 - sequential_1_loss: 0.2986 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8727 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9118 - sequential_1_loss: 0.3290 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8834 - sequential_1_loss: 0.2746 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8944 - sequential_1_loss: 0.2873 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8540 - sequential_1_loss: 0.2893 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9001 - sequential_1_loss: 0.3115 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8515 - sequential_1_loss: 0.2873 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8946 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9102 - sequential_1_loss: 0.3148 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8858 - sequential_1_loss: 0.3006 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8539 - sequential_1_loss: 0.2783 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9238 - sequential_1_loss: 0.3083 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9517 - sequential_1_loss: 0.3223 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9547 - sequential_1_loss: 0.3200 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9498 - sequential_1_loss: 0.3161 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9287 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8584 - sequential_1_loss: 0.2786 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9080 - sequential_1_loss: 0.2941 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9215 - sequential_1_loss: 0.3244 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8851 - sequential_1_loss: 0.2944 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9126 - sequential_1_loss: 0.3165 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8924 - sequential_1_loss: 0.2814 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 6ms/step - loss: 0.8818 - sequential_1_loss: 0.2954 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9034 - sequential_1_loss: 0.3061 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9106 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9004 - sequential_1_loss: 0.2920 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9171 - sequential_1_loss: 0.2881 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8894 - sequential_1_loss: 0.2946 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9012 - sequential_1_loss: 0.3185 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8685 - sequential_1_loss: 0.2881 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9069 - sequential_1_loss: 0.3039 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9209 - sequential_1_loss: 0.3073 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8929 - sequential_1_loss: 0.3000 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8902 - sequential_1_loss: 0.2939 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9042 - sequential_1_loss: 0.3098 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9126 - sequential_1_loss: 0.3173 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8740 - sequential_1_loss: 0.2687 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8988 - sequential_1_loss: 0.2996 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9279 - sequential_1_loss: 0.3048 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8993 - sequential_1_loss: 0.2977 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8823 - sequential_1_loss: 0.3103 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8825 - sequential_1_loss: 0.2843 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9061 - sequential_1_loss: 0.2845 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9025 - sequential_1_loss: 0.2916 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9235 - sequential_1_loss: 0.3159 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8974 - sequential_1_loss: 0.2903 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9580 - sequential_1_loss: 0.3104 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8706 - sequential_1_loss: 0.2672 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8651 - sequential_1_loss: 0.2747 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8889 - sequential_1_loss: 0.2915 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9111 - sequential_1_loss: 0.3082 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9208 - sequential_1_loss: 0.2903 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8919 - sequential_1_loss: 0.3002 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8956 - sequential_1_loss: 0.3136 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9153 - sequential_1_loss: 0.3137 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8422 - sequential_1_loss: 0.2852 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.9052 - sequential_1_loss: 0.3063 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9061 - sequential_1_loss: 0.3147 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9146 - sequential_1_loss: 0.3059 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8974 - sequential_1_loss: 0.2839 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9069 - sequential_1_loss: 0.2850 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8918 - sequential_1_loss: 0.2815 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9127 - sequential_1_loss: 0.3037 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 5ms/step - loss: 0.8697 - sequential_1_loss: 0.2750 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8796 - sequential_1_loss: 0.2890 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9233 - sequential_1_loss: 0.3007 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8882 - sequential_1_loss: 0.2989 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0000e+00 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8845 - sequential_1_loss: 0.2843 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8954 - sequential_1_loss: 0.3010 - sequential_1_acc: 0.2143 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9152 - sequential_1_loss: 0.3147 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9242 - sequential_1_loss: 0.2895 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8663 - sequential_1_loss: 0.2704 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8763 - sequential_1_loss: 0.2966 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9002 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - sequential_1_loss: 0.2876 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8721 - sequential_1_loss: 0.2972 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8771 - sequential_1_loss: 0.2909 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9225 - sequential_1_loss: 0.3036 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9217 - sequential_1_loss: 0.3188 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8875 - sequential_1_loss: 0.3025 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8555 - sequential_1_loss: 0.3062 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8822 - sequential_1_loss: 0.2856 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8986 - sequential_1_loss: 0.3231 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1429 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8809 - sequential_1_loss: 0.2818 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9373 - sequential_1_loss: 0.3033 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8775 - sequential_1_loss: 0.2827 - sequential_1_acc: 0.0000e+00 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0000e+00 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8984 - sequential_1_loss: 0.2991 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8841 - sequential_1_loss: 0.2841 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.1786 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - sequential_1_loss: 0.3072 - sequential_1_acc: 0.0357 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0357 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8821 - sequential_1_loss: 0.2932 - sequential_1_acc: 0.1786 - sequential_1_acc_1: 0.1071 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8882 - sequential_1_loss: 0.2784 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0714 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.9335 - sequential_1_loss: 0.3120 - sequential_1_acc: 0.1071 - sequential_1_acc_1: 0.1786 - sequential_1_acc_2: 0.1071 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8703 - sequential_1_loss: 0.2889 - sequential_1_acc: 0.1429 - sequential_1_acc_1: 0.1429 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00
Train on 28 samples, validate on 4 samples
Epoch 1/1
28/28 [==============================] - 0s 4ms/step - loss: 0.8870 - sequential_1_loss: 0.3088 - sequential_1_acc: 0.0714 - sequential_1_acc_1: 0.0357 - sequential_1_acc_2: 0.0714 - val_loss: 0.9000 - val_sequential_1_loss: 0.3000 - val_sequential_1_acc: 0.0000e+00 - val_sequential_1_acc_1: 0.0000e+00 - val_sequential_1_acc_2: 0.0000e+00